\documentclass[chaparabic,mmi,ms,12pt,single]{metu} 
\usepackage{appendix}
\usepackage{longtable}
\usepackage[pdftex]{hyperref}
\usepackage[all]{hypcap}
\usepackage{todonotes}
\graphicspath{ {./../01metu-msc-thesis/images/} }
\usepackage[figuresright]{rotating}
\usepackage{xy} 
\usepackage{booktabs}
\usepackage{pifont}
\usepackage{color}
\usepackage{listings}
\usepackage{pdfpages}
\usepackage{array}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{float}
\usepackage{caption}
\usepackage{lastpage}
\usepackage{afterpage}
\usepackage{lipsum}
\usepackage{adjustbox}
\usepackage{rotating}
\usepackage{pdflscape}
\usepackage{hypcap}
\usepackage{threeparttable}

\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{amsmath,amssymb} % define this before the line numbering.
% \usepackage{ruler}
\usepackage{color}
% \usepackage{cite}
% \usepackage[utf8x]{inputenc}
% \usepackage{footnote}
% \makesavenoteenv{tabular}
% \makesavenoteenv{table}

\renewcommand{\sectionautorefname}{\S}
\renewcommand{\subsectionautorefname}{\S}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\captionsetup{belowskip=12pt,aboveskip=8pt}
\newcommand{\tab}{\hspace*{2em}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\DeclareCaptionLabelFormat{continued}{#1~#2 (Continued)}

\usepackage{amsmath}
\usepackage{siunitx}
\usepackage{textcomp}
\usepackage{subcaption}


\usepackage{tikz}
\usepackage{mathtools}
\usepackage{rotating}
%\PassOptionsToPackage{figuresright}{rotating}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\usepackage{multirow}
\usepackage{hvfloat}

\newcommand{\EA}[1]{\textcolor{red}{[EA: #1]}}

% Name and Surname
\author{Aytekin Erdogan} % Change this
% Thesis Title English and Turkish
\title{A Transformer-Based Approach for Fusing Infrared and Visible Band Images} % Change this
\turkishtitle{Kızılötesi ve Görünür Bant Görüntülerin Birleştirilmesi İçin Transformer Tabanlı Bir Yaklaşım} % Change this

\date{August 2023} % Change this

 
% prof : Prof. Dr.
% assocprof : Assoc. Prof. Dr.
% assistprof : Assist. Prof. Dr.
% dr : Dr.
%
% Director of Institute
\director[prof]{ Banu GÜNEL KILIÇ} % Change this
% Head of Department
\headofdept[assocprof]{Elif SÜRER} % Change this
%
% Supervisor : English and Turkish
\supervisor[assocprof]{Elif SÜRER} % Change this
% \turkishsupervisor{  } %if you will hard-code the academic title
%
% Affiliation of Supervisor in English and possibly in Turkish
\departmentofsupervisor{Multimedia Informatics, METU} % Change this

\cosupervisor[assocprof]{Erdem AKAGÜNDÜZ} % Change this
\departmentofcosupervisor{Multimedia Informatics, METU} % Change this
%
% Committee Members
% In general members are sorted according to their academic titles
%
% Proffesors (1)
% Associate Professors (2)
% Assistant Professors (3)
% Other (4)
% 
% IMPORTANT:  All affiliatons should fit in a single line
% If affiliation line is broken into two lines you should shorten the affiliation by using 
% abbrevations or any other means
%
% First committee member should be the chair of examining committee
% Typically the chair is one of the highest ranked committee members
% Ask your supervisor if you are not sure
\committeememberi[prof]{Alptekin TEMİZEL} % Change this
\affiliationi{Multimedia Informatics, METU} % Change this
% Second committee member is always your supervisor
\committeememberii[assocprof]{Elif SÜRER} % Change this
\affiliationii{Multimedia Informatics, METU} % Change this
% If you are an M.Sc. student and your Co-Supervisor is in your 
% examination committee, then third committee member is always your co-supervisor
%
% IMPORTANT: If you are Ph.D. student your co-supervisor can not be in your 
% examination committee.

% \def\@proftitlename{Prof. Dr.}\def\@tproftitlename{Prof. Dr.}
% \def\@assocproftitlename{Assoc. Prof. Dr.}\def\@tassocproftitlename{Doç. Dr.}
% \def\@assistproftitlename{Assist. Prof. Dr.}\def\@tassistproftitlename{Yrd. Doç. Dr.}
% \def\@drtitlename{Dr.}\def\@tdrtitlename{Dr.}

\committeememberiii[assocprof]{İrem ÜLKÜ} % Change this
\affiliationiii{Computer Engineering, Ankara University} % Change this
% % Fourth committee member
% \committeememberiv[assistprof]{Committee Member 4} % Change this
% \affiliationiv{Department, School} % Change this
% % Fifth committee member
% \committeememberv[assistprof]{Committee Member 5} % Change this
% \affiliationv{Department, School} % Change this
%
% Keywords : English & Turkish, Comma seperated
\keywords{Image Fusion, Visual Infrared Image Fusion, Transformer Based Image Fusion, Structural Similarity Metric} % Change this
\anahtarklm{Görüntü Füzyonu, Görsel Kızılötesi Görüntü Füzyonu, Transformer Tabanlı Görüntü Füzyonu, Yapısal Benzerlik Ölçütü.} % Change this
%
% Abstract in English
%
\abstract{
  Image fusion is a process where images obtained from different sensors are combined to generate a single image that benefits from complementary information. Recently, there has been a growing interest in image fusion, which involves fusing images from diverse sensors to produce an enhanced image. Although deep learning methods have been widely employed in state-of-the-art techniques to extract meaningful features for image fusion, these methods primarily focus on integrating local features while disregarding the broader context within the image. To overcome this limitation, Transformer-based models have emerged as a promising solution, aiming to capture general context dependencies through attention mechanisms. Inspired by this, we propose a novel image fusion approach that incorporates a transformer-based multi-scale fusion strategy, effectively considering both local and general context information, thus enhancing the overall fusion process. Our proposed method follows a two-stage training approach, where an auto-encoder is initially trained to extract deep features at multiple scales. Subsequently, the multi-scale features are fused using a combination of Convolutional Neural Networks (CNNs) and Transformers. The CNNs are utilized to capture local features, while the Transformer handles the integration of general context features. Notably, in contrast to similar methods, we propose novel loss functions to address the challenges associated with defining a loss function when ground truth for fusion is absent. Through extensive experiments on various benchmark datasets, our proposed method, along with the novel loss function definition, demonstrates superior performance compared to other competitive fusion algorithms. Overall, this thesis presents significant advancements in image fusion techniques, offering innovative approaches and contributing to the state-of-the-art in this field.
} % Change this
%
% Turkish Abstract
%
\oz{
  Görüntü füzyonu, farklı sensörlerden elde edilen görüntülerin birleştirilerek tamamlayıcı bilgilerden yararlanan tek bir görüntü oluşturulması sürecidir. Son zamanlarda, farklı sensörlerden elde edilen görüntülerin birleştirilerek geliştirilmiş bir görüntü elde etme konusunda büyük bir ilgi artışı yaşanmaktadır. Derin öğrenme yöntemleri, görüntü füzyonu için anlamlı özelliklerin çıkarılmasında yaygın olarak kullanılmaktadır; ancak bu yöntemler genellikle yerel özelliklerin entegrasyonuna odaklanırken görüntünün daha geniş bağlamını dikkate almamaktadır. Bu kısıtlamayı aşmak için Transformer tabanlı modeller, dikkat mekanizmaları aracılığıyla genel bağlamlı bağımlılıkları yakalamayı hedefleyen umut vaat eden bir çözüm olarak ortaya çıkmıştır. Bu doğrultuda, yerel ve genel bağlam bilgisini etkili bir şekilde dikkate alan bir transformer tabanlı çok ölçekli füzyon stratejisi içeren yeni bir görüntü füzyon yaklaşımı önermekteyiz. Önerdiğimiz yöntem, ilk aşamada bir otokodlayıcı ile çok ölçekli derin özelliklerin çıkarılmasını sağlayan iki aşamalı bir eğitim yaklaşımını takip etmektedir. Ardından, çok ölçekli özellikler, Konvolüsyonel Sinir Ağları (CNN'ler) ve Transformer'ların bir kombinasyonu kullanılarak birleştirilmektedir. CNN'ler yerel özellikleri yakalamak için kullanılırken, Transformer genel bağlam özelliklerini entegre etmekten sorumludur. Benzer yöntemlere kıyasla, füzyon için gerçek değeri olmayan bir kayıp fonksiyonu tanımlama zorluklarını ele almak için yeni kayıp fonksiyonları önermekteyiz. Çeşitli benchmark veri kümeleri üzerinde yapılan kapsamlı deneylerle, önerilen yöntemimiz ve yeni kayıp fonksiyonu tanımı, diğer rekabetçi füzyon algoritmalarına kıyasla üstün performans sergilemektedir. Genel olarak, bu tez, görüntü füzyon tekniklerinde önemli ilerlemeler sunmakta, yenilikçi yaklaşımlar sunmakta ve bu alandaki en son teknolojiye katkıda bulunmaktadır.
} % Change this
%
% Dedications
\dedication{To those noble souls who, with selfless ardor, dedicate their entire lives for the betterment of humanity's plight} % Change this
%
%
% Acknowledgements   
\acknowledgments{
I want to express my deep gratitude to the remarkable individuals and organizations whose unwavering support made this thesis possible.

First and foremost, I want to thank the entire academic community at \textbf{Middle East Technical University}, especially my thesis advisors, \textbf{Assoc. Prof. Erdem Akagündüz} and  \textbf{Assoc. Prof. Elif Sürer}, for their invaluable guidance and insightful contributions to this research.

With utmost gratitude, I acknowledge \textbf{The Scientific and Technological Research Council of Turkey (TUBITAK)} for granting me the esteemed 2210A - Domestic Graduate Scholarship, which has been instrumental in funding this research endeavor. 

I am also immensely thankful to the \textbf{Raventech Inc} for their collaboration, providing access to their real-world data and powerful computational resources that significantly elevated the quality and efficiency of this study.

% In addition, I must mention the \textbf{BlueJay Coffee House}, where I found a haven during this research journey. Their delicious coffee made from unique beans from around the world kept me energized and focused.

% To an \textbf{anonymous friend}, I owe my gratitude for unknowingly providing comfort and peace through their friendly smile and presence during this demanding process.

Lastly, To my \textbf{family and friends}, I am deeply indebted for their unwavering encouragement and support in every step of this academic pursuit.

With heartfelt appreciation, I recognize the profound impact each of you has had on this academic journey, and I am truly grateful for your invaluable contributions.
} % Change this

%
% End of Personal and Introductory Information
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
\begin{document}
% Preliminaries
\begin{preliminaries}
% If you are willing to use any custom stuff before Chapters, put it here
% Such as List of Abbreviations
% Check the abbreviations.tex for a template list of abbreviations

\input{abbreviations.tex}
% End of Preliminaries
\end{preliminaries}
%   
% Latex content Goes Here 
% 
%

\setlength{\parindent}{0em}
\setlength{\parskip}{10pt}

% You can add as many chapters
% Change this
\input{chapters/chapter1.tex}
\input{chapters/chapter2.tex}
\input{chapters/chapter3.tex}
\input{chapters/chapter4.tex}
\input{chapters/chapter5.tex}
\input{chapters/chapter6.tex}


\input{references.tex}

%
% References in Bibtex format goes into below indicated file with .bib extension
%\bibliography{thesis_references}
% You can use full name of authors, however most likely some of the Bibtex entries you will find, will use abbreviated first names
% If you don't want to correct each of them by hand, you can use abbreviated style for all of the references

%\bibliographystyle{abbrv}

% if you have more that one appendix, then use \appendices, otherwise use 
% \appendix
% \input{appendix/appendix1.tex}

% \appendix
% \input{appendix/appendix1.tex}
% \input{appendix/appendix2.tex}
% \input{appendix/appendix3.tex}
%\input{chapters/vita.tex}
\end{document}