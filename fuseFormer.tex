\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{subcaption}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{FuseFormer: A Transformer For Visual and Infrared Image Fusion\\
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Aytekin Erdogan}
\IEEEauthorblockA{\textit{Graduate School of Informatics} \\
\textit{Middle East Technical University}\\
Ankara, Turkey \\
aytekin.erdogan@metu.edu.tr}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Erdem Akagunduz}
\IEEEauthorblockA{\textit{Graduate School of Informatics} \\
\textit{Middle East Technical University}\\
Ankara, Turkey \\
akaerdem@metu.edu.tr}
}

\maketitle

\begin{abstract}
    Image fusion combines data from different sensors to create a single image with enriched information. Despite the widespread use of deep learning in image fusion, current methods often focus on local features, neglecting broader contextual information. Addressing this limitation, we introduce a novel image fusion approach employing a transformer-based multi-scale strategy. This method captures both local and general context, improving overall fusion. Our two-stage training involves an auto-encoder for deep feature extraction and subsequent fusion of multi-scale features using Convolutional Neural Networks (CNNs) and Transformers. Unlike comparable approaches, we propose innovative loss functions to tackle the challenge of fusion without ground truth. Through extensive experiments on benchmark datasets, our method, coupled with the newly defined loss functions, outperforms other fusion algorithms.
    % This thesis marks a significant advancement in image fusion, contributing novel techniques and enhancing the state-of-the-art in the field.
\end{abstract}

\begin{IEEEkeywords}
Image Fusion, Visual Infrared Image Fusion, Transformer Based Image Fusion, Structural Similarity Metric
\end{IEEEkeywords}


\section{Introduction}
\input{chapters/1introduction.tex}

\section{Related Work}
\input{chapters/chapter2}

\section{Methodology}
\input{chapters/chapter3}

\bibliographystyle{ieeetr} 
\bibliography{thesis}

\end{document}
